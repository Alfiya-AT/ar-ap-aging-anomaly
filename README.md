# AP/AR Aging & Anomaly Detection System

This project is an automated system designed to monitor Accounts Payable (AP) and Accounts Receivable (AR) data. It helps finance teams identify risks early by analyzing aging invoices, detecting anomalies using Machine Learning and rule-based logic, and visualizing insights through an interactive dashboard.

## ğŸš€ Key Features

### 1. Data Ingestion & Processing (ETL)
-   **Data Collection**: Ingests AP/AR data from CSV files (extensible to databases).
-   **Cleaning**: Standardizes dates, handles missing values, and prepares data for analysis.
-   **Pipeline**: Automated ETL pipeline (`src/etl/pipeline.py`) to transform raw data into a clean format.

### 2. Aging Analysis
-   **Aging Calculation**: Automatically calculates invoice age and categorizes them into standard buckets:
    -   0â€“30 days
    -   31â€“60 days
    -   61â€“90 days
    -   90+ days
-   **Metrics**: Computes total outstanding amounts and overdue balances.

### 3. Anomaly Detection
The system employs a hybrid approach to find risky items:
-   **Rule-Based Detection** (`src/analysis/rules.py`):
    -   **Duplicate Invoices**: Detects potential duplicates based on entity, amount, and date.
    -   **High Value Spikes**: Flags invoices significantly above the 98th percentile.
    -   **Weekend Invoices**: Identifies invoices dated on weekends (often a red flag for fraud or errors).
-   **ML-Based Detection** (`src/analysis/ml_model.py`):
    -   **Isolation Forest**: Unsupervised learning model to detect statistical outliers based on amount, month, and day-of-week patterns.

### 4. Interactive Dashboard
A **Streamlit** dashboard (`src/ui/dashboard.py`) provides real-time visibility:
-   **KPIs**: Total AP/AR, Overdue Amounts.
-   **Visualizations**: Aging bucket bar charts and daily invoice trend lines.
-   **Anomaly Explorer**: Filterable table of detected anomalies with severity scores (High/Medium/Low).
-   **Actions**: Download anomaly reports as CSV.

### 5. Alerts & Reporting
-   **Email Alerts**: Configuration to send notifications for high-risk anomalies.
-   **Reporting**: Generates detailed reports explaining why an invoice was flagged.

---

## ğŸ“‚ Project Structure

```
ar-ap-aging-anomaly/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Input CSV files (ap_data_sample.csv, ar_data_sample.csv)
â”‚   â””â”€â”€ processed/            # Cleaned data generated by the ETL pipeline
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ analysis/             # Logic for aging, ML models, and rules
â”‚   â”‚   â”œâ”€â”€ aging.py
â”‚   â”‚   â”œâ”€â”€ ml_model.py       # Isolation Forest implementation
â”‚   â”‚   â””â”€â”€ rules.py          # Business rules for anomalies
â”‚   â”œâ”€â”€ etl/                  # Data ingestion and cleaning pipeline
â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”œâ”€â”€ reporting/            # Alerting and reporting modules
â”‚   â”‚   â””â”€â”€ alerts.py
â”‚   â””â”€â”€ ui/                   # Dashboard application
â”‚       â””â”€â”€ dashboard.py
â”œâ”€â”€ main.py                   # Entry point for running the ETL pipeline
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # Project documentation
```

---

## ğŸ› ï¸ Installation

1.  **Clone the repository**:
    ```bash
    git clone <repository_url>
    cd ar-ap-aging-anomaly
    ```

2.  **Set up a virtual environment** (optional but recommended):
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

---

## âš¡ Usage

### Step 1: Prepare Data
Ensure your raw data files (`ap_data_sample.csv` and `ar_data_sample.csv`) are placed in the `data/raw/` directory.

### Step 2: Run the ETL Pipeline
Process the raw data to clean it and calculate initial metrics.
```bash
python main.py
```
*This will generate cleaned files in `data/processed/`.*

### Step 3: Launch the Dashboard
Start the Streamlit application to view insights and anomalies.
```bash
streamlit run src/ui/dashboard.py
```
The dashboard will open in your default web browser (usually at `http://localhost:8501`).

---

## ğŸ§° Tech Stack

-   **Language**: Python 3.x
-   **Data Processing**: Pandas, NumPy
-   **Machine Learning**: Scikit-learn (Isolation Forest)
-   **Visualization**: Plotly, Streamlit
-   **Utilities**: Faker (for data generation), smtplib (for alerts)
